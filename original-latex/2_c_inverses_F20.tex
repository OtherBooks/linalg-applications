\achapter{10}{The Inverse of a Matrix} \label{sec:matrix_inverse}

\vspace*{-17 pt}
\framebox{
\parbox{\dimexpr\linewidth-3\fboxsep-3\fboxrule}
{\begin{fqs}
\item What does it mean for a matrix $A$ to be invertible? 
\item How can we tell when an $n \times n$ matrix $A$ is invertible?
\item If an $n \times n$ matrix $A$ is invertible, how do we find the inverse of $A$?
\item If $A$ and $B$ are invertible $n \times n$ matrices, why is $AB$ invertible and what is $(AB)^{-1}$?
\item How can we use the inverse of a matrix in solving matrix equations?
\end{fqs}}}% \hspace*{3 pt}}

\vspace*{13 pt}


\csection{Application: Modeling an Arms Race}

Lewis Fry Richardson was a Quaker by conviction who was deeply troubled by the major wars that had been fought in his lifetime. Richardson's training as a physicist led him to believe that the causes of war were phenomena that could be quantified, studied, explained, and thus controlled. He collected considerable data on wars and constructed a model to represent an arms race. The equations in his model caused him concern about the future as indicated by the following statement:  
\begin{quote} But it worried him that the equations also showed that the unilateral disarmament of Germany after 1918, enforced by the Allied Powers, combined with the persistent level of armaments of the victor countries would lead to the level of Germany’s armaments growing again. In other words, the post-1918 situation was not stable. From the model he concluded that great statesmanship would be needed to prevent an unstable situation from developing, which could only be prevented by a change of policies.\footnote{\emph{Nature} \textbf{135}, 830-831 (18 May 1935) ``Mathematical Psychology of War" (3420).}
\end{quote}
Analyzing Richardson's arms race model utilizes matrix operations, including matrix inverses. We explore the basic ideas in Richardson's model later in this section. 


\csection{Introduction}

To this point we have solved systems of linear equations with matrix forms $A \vx = \vb$ by row reducing the augmented matrices $[A \ | \ \vb]$. These linear matrix-vector equations should remind us of linear algebraic equations of the form $ax = b$, where $a$ and $b$ are real numbers. Recall that we solved an equation of the form $ax=b$ by dividing both sides by $a$ (provided $a \neq 0$), giving the solution $x = \frac{b}{a}$, or equivalently $x = a^{-1}b$. The important property that the number $a^{-1}$ has that allows us to solve a linear equation in this way is that $a^{-1}a = 1$, so that $a^{-1}$ is the multiplicative inverse of $a$. We can solve certain types of matrix equations $A \vx = \vb$ in the same way, provided we can find a matrix $A^{-1}$ with similar properties. We investigate this situation in this section.

\begin{pa} \label{pa:2_c} ~
\be
\item Before we define the inverse matrix, recall that the identity matrix $I_n$ (with 1's along the diagonal and 0's everywhere else) is a multiplicative identity in the set of $n \times n$ matrices (just like the real number 1 is the multiplicative identity in the set of real number). In particular, $I_nA = AI_n = A$ for any $n \times n$ matrix $A$. 

Now we can generalize the inverse operation to matrices. For an $n\times n$ matrix $A$, we define $A^{-1}$ to be the matrix which when multiplied by $A$ gives us the identity matrix. In other words, $AA^{-1}=A^{-1}A=I_n$. We can find the inverse of a matrix in a calculator by using the $x^{-1}$ button.

For each of the following matrices, determine if the inverse exists using your calculator or other appropriate technology. If the inverse does exist, write down the inverse and check that it satisfies the defining property of the inverse matrix, that is $AA^{-1}=A^{-1}A=I_n$. If the inverse doesn't exist, write down any error you received from the technology. Can you guess why the inverse does not exist for these matrices? \\

\ba
\begin{minipage}{2.0in}
\item $A = \left[ \begin{array}{cc} 1&3 \\ 0&4 \end{array} \right]$
\end{minipage}
\begin{minipage}{2.0in}
\item $A = \left[ \begin{array}{cc} 2&3 \\ 4&6 \end{array} \right]$
\end{minipage}

\begin{minipage}{2.0in}
\item $A = \left[ \begin{array}{rrc} 1&2&3 \\ -1&-1&2\\1&2&2 \end{array} \right]$
\end{minipage}
\begin{minipage}{2.0in}
\item $A = \left[ \begin{array}{rrc} 1&2&3 \\ 2&4&6\\1&2&2 \end{array} \right]$
\end{minipage}

\begin{minipage}{2.0in}
\item $A = \left[ \begin{array}{rrc} 1&0&0 \\ 0&2&0\\0&0&3 \end{array} \right]$
\end{minipage}
\begin{minipage}{2.0in}
\item $A = \left[ \begin{array}{rrc} 1&2&3 \\ -1&-1&2\\0&1&5 \end{array} \right]$
\end{minipage}

\ea

\item Now we turn to the question of how to find the inverse of a matrix in general. With this approach, we will be able to determine which matrices have inverses as well. 

We will consider the $2 \times 2$ case to make the calculations easier. Suppose $A$ is a $2 \times 2$ matrix. Our goal is to find a matrix $B$ so that $AB = I_2$ and $BA = I_2$. If such a matrix exists, we will call $B$ the inverse, $A^{-1}$, of $A$. 
	\ba
	\item What does the equation $AB = I_2$ tell us about the size of the matrix $B$?
		

	\item Now let $A = \left[ \begin{array}{cc} 1&2 \\ 1&3 \end{array} \right]$. We want to find a  matrix $B$ so that $AB = I_2$. Suppose $B$ has columns $\vb_1$ and $\vb_2$, i.e. $B = [\vb_1 \ \vb_2]$. Our definition of matrix multiplication shows that 
	\[AB = [A\vb_1 \ A\vb_2].\]
		\begin{enumerate}[i.]
		\item If $AB = I_2$, what must $A\vb_1$ and $A \vb_2$ equal? 
		
		\item Use the result from part (a) to set up two matrix equations to solve to find $\vb_1$ and $\vb_2$. Then find $\vb_1$ and $\vb_2$. As a result, find the matrix $B$.

		\item When we solve the two systems we have found a matrix $B$ so that $AB = I_2$. Is this enough to say that $B$ is the inverse of $A$? If not, what else do we need to know to verify that $B$ is in fact $A^{-1}$? Verify that $B$ is $A^{-1}$. 
	
		\end{enumerate}
	\ea

\item A matrix inverse is extremely useful in solving matrix equations and can help us in solving systems of equations. Suppose that $A$ is an invertible matrix, i.e., there exists $A^{-1}$ such that $AA^{-1}=A^{-1}A=I_n$.

\ba 

\item Consider the system $A\vx=\vb$. Use the inverse of $A$ to show that this system has a solution for every $\vb$ and find an expression for this solution in terms of $\vb$ and $A^{-1}$. (Note that since matrix multiplication is not commutative, we have to pay attention to the order in which we multiply matrices. For example, $A^{-1}AB=B$ while we cannot simplify $ABA^{-1}$ to $B$ unless $A$ and $B$ commute.)

\item If $A$, $B$, and $C$ are matrices and $A+C = B+C$, then we can subtract the matrix $C$ from both sides to see that $A = B$. We saw in Section \ref{sec:matrix_operations} that there is no corresponding general cancellation property for matrix multiplication when we found that $AB=AC$ could hold while $B\neq C$. However, we can cancel $A$ from this equation in certain circumstances. Suppose that $AB=AC$ and that $A$ is an invertible matrix. Show that we can cancel $A$ in this case and conclude that $B=C$. (Note: When simplifying the product of matrices, again keep in mind that matrix multiplication is not commutative.)

\ea

\ee

\end{pa}


\csection{Invertible Matrices} 

We now have an algebra of matrices in that we can add, subtract, and multiply matrices of the correct sizes. But what about division? In our early mathematics education we learned about \emph{multiplicative inverses} (or reciprocals) of real numbers. The multiplicative inverse of a number $a$ is the real number which when multiplied by $a$ produces 1, the multiplicative identity of real numbers. This inverse is denoted $a^{-1}$. For example, the multiplicative inverse of $2$ is $2^{-1}=\frac{1}{2}$ because 
\[2\cdot \frac{1}{2} = 1 = \frac{1}{2}\cdot 2.\]
Of course, we didn't have to write both products because multiplication of real numbers is a commutative operation.  There are a couple of important things to note about multiplicative inverses -- we can use the inverses of the number $a$ to solve the simple linear equation $ax+b = c$ for $x$ ($x = a^{-1}(c-b)$), and not every real number has an inverse. The latter means that the inverse is not defined on the entire set of real numbers. We can extend the idea of inverses to matrices, although we will see that there are many more matrices than just the zero matrix that do not have inverses.

To define matrix inverses\footnote{We usually refer to a multiplicative inverse as just an inverse. Since every matrix has an additive inverse, there is no need to consider the existence of additive inverses.} we make an analogy with the property of inverses in the real numbers: $x\cdot x^{-1}=1=x^{-1}\cdot x$. 



\begin{definition} Let $A$ be an $n \times n$ matrix.
\begin{enumerate}
\item $A$ is \textbf{invertible}\index{matrix!invertible} if there is an $n \times n$ matrix $B$ so that $AB = BA = I_n$. 
\item If $A$ is invertible, an \textbf{inverse}\index{matrix!inverse} of $A$ is a matrix $B$ such that $AB = BA = I_n$. 
\end{enumerate} 
\end{definition}



If an $n \times n$ matrix $A$ is invertible, its inverse will be unique (see Exercise \ref{ex:2_c_unique_inverse}), and we denote the inverse of $A$ as $A^{-1}$. We also call an invertible matrix a \emph{non-singular}\index{matrix!non-singular} matrix (with \emph{singular}\index{matrix!singular} meaning non-invertible). 



\begin{activity} \label{act:2_c_1} ~
	\ba
	\item Let $A = \left[ \begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array} \right]$. Calculate $AB$ where $B = \left[ \begin{array}{cc} a&b \\ c&d \end{array} \right]$. Using your result, explain why it is not possible to have $AB=I_2$, showing that $A$ is non-invertible. 



\item Calculate $AB$ where $A = \left[ \begin{array}{cc} 1 & 2 \\ 2 & 4 \end{array} \right]$ and $B = \left[ \begin{array}{cc} a&b \\ c&d \end{array} \right]$. Using your result, explain why the inverse of $A$ doesn't exist.

	
	
	\ea
	
\end{activity}

We saw in Activity \ref{act:2_c_1} why the inverse does not exist for two specific matrices. We will find in the next section an easy criterion for determining when a matrix has an inverse. In short, when the RREF of the matrix has a pivot in every column and row, then the matrix will be invertible. We know that this condition relates to quite a few other linear algebra concepts we have seen so far, such as linear independence of columns and the columns spanning $\R^n$. We will put these criteria together in one big theorem in the next section.



\begin{activity} \label{act:2_c_2} Suppose that $A$ is an invertible $n \times n$ matrix. Hence we have an inverse matrix $A^{-1}$ for which $AA^{-1}=A^{-1}A=I_n$. We will see how the inverse is useful in solving matrix equations involving $A$.

	\ba
	\item Explain why the matrix expressions 
\[\ A^{-1}(AB) , \ A^{-1}(A(BA)A^{-1}) \ \text{ and } \ BA^{-1}BAA^{-1}B^{-1}A\]
can all be simplified to $B$. (Hint: Use the associative property of matrix multiplication.)
	
	
	
	\item Suppose the system $A \vx = \vb$ has a solution. Explain why then $A^{-1}(A\vx)= A^{-1}\vb$. What does this equation simplify to?
	
	
	
	\item Since we found one single expression for the solution $\vx$ in equation $A\vx=\vb$, this implies that the equation has a unique solution. What does this imply about the matrix $A$? 
	
	
	
	\ea
	
\end{activity}



As we saw in Preview Activity \ref{act:2_c_1}, if the $n \times n$ matrix $A$ is invertible, then the equation $A \vx = \vb$ is consistent for all $\vb$ in $\R^n$ and has the unique solution $\vx = A^{-1} \vb$. This means that $A$ has a pivot in every row and column, which is equivalent to the criterion that $A$ reduces to $I_n$, as we noted above. 

Even though $\vx=A^{-1}\vb$ is an explicit expression for the solution of the system $A\vx=\vb$, using the inverse of a matrix is usually not a computationally efficient way to solve a matrix equation. Finding the RREF of a matrix computationally takes fewer steps to solve the matrix equation. 


\csection{Finding the Inverse of a Matrix}

The next questions for us to address are how to tell when a matrix is invertible and how to find the inverse of an invertible matrix. Consider a $2 \times 2$ matrix $A$. To find the inverse matrix $B = [\vb_1 \ \vb_2]$ of $A$, we have to solve the two matrix-vector equations $A \vb_1 = \begin{bmatrix}1 \\ 0 \end{bmatrix}$ and $A \vb_2= \begin{bmatrix}0 \\1 \end{bmatrix}$ to find the columns of $B$. Since $A$ is the coefficient matrix for both systems, we apply the same row operations on both systems to reduce $A$ to RREF. Thus, instead of solving the two matrix-vector equations separately, we could simply have found the RREF of 
\[\left[\, A \ \left| \begin{array}{cc} 1 & 0 \\ 0 & 1 \end{array}\right. \right]\]
and done all of the work in one pass. Note that the right hand side of the augmented matrix is now $I_2$. So we row reduce $[A \ | \ I_2]$, and if the systems are consistent, the reduced row echelon form of $[A \ | \ I_2]$ must be $[I_2 \ | \ A^{-1}]$.  You should be able to see that this same process works in any dimension. 



\noindent \textbf{How to find the inverse of an $n \times n$ matrix $A$:}
\begin{itemize}
\item Augment $A$ with the identity matrix $I_n$.
\item Apply row operations to reduce the augmented matrix $[A \ | \ I_n]$. If the system is consistent, then the reduced row echelon form of $[A \ | \ I_n]$ will have the form $[I_n \ | \ B]$ (by Activity \ref{act:2_c_1} (d)). If the reduced row echelon form of $A$ is not $I_n$, then this step fails and $A$ is not invertible.
\item If $A$ is row equivalent to $I_n$, then the matrix $B$ in the second step has the property that $AB = I_n$. We will show later that the matrix $B$ also satisfies $BA = I_n$ and so $B$ is the inverse of $A$.
\end{itemize}



\begin{activity}  \label{act:2_c_3} Find the inverse of each matrix \underline{using the method above}, if it exists. Compare the result with the inverse that you get from using appropriate technology to directly calculate the inverse. 
\ba
\item $\left[ \begin {array}{crr} 1&1&1\\ 1&1&-1\\ 1&-1&0 \end {array} \right]$



\item $\left[ \begin {array}{cccc} 1&1&1\\ 2&2&2\\ 0&0&1 \end {array} \right]$

\ea

\end{activity}



We can use this method of finding the inverse of a matrix to derive a concrete formula for the inverse of a $2 \times 2$ matrix: 
\begin{equation} \label{eq:2_c_1}
\left[ \begin{array}{cc} a&b \\ c&d \end{array} \right]^{-1} = \frac{1}{ad-bc} \left[ \begin{array}{rr} d&-b \\ -c&a \end{array} \right],
\end{equation}
provided that $ad-bc \neq 0$ (see Exercise \ref{ex:2_c_2by2_inverse}). Hence, any $2\times 2$ matrix $\left[ \begin{array}{cc} a&b \\ c&d \end{array} \right]$ has an inverse if and only if $ad-bc\neq 0$. We call this quantity \emph{determinant of $A$}, $\det(A)$. We will see that the determinant of a general $n\times n$ matrix will be essential in determining invertibility of the matrix.


\csection{Properties of the Matrix Inverse}

As we have done with every new operation, we ask what properties the inverse of a matrix has. 



\begin{activity} \label{act:2_c_5} Consider the following questions about matrix inverses. If two $n \times n$ matrices $A$ and $B$ are invertible, is the product $AB$ invertible? If so, what is the inverse of $AB$? We answer these questions in this activity.
\ba
\item Let 
\[A = \left[ \begin{array}{cc} 1&2\\1&3 \end{array} \right] \ \ \text{ and }  B = \left[ \begin{array}{rc} 2&3\\-1&2 \end{array} \right].\]
	\begin{enumerate}[i.]
	\item Use formula (\ref{eq:2_c_1}) to find the inverses of $A$ and $B$.



	\item Find the matrix product $AB$. Is $AB$ invertible? If so, use formula (\ref{eq:2_c_1}) to find the inverse of $AB$.



	\item Calculate the products $A^{-1}B^{-1}$ and $B^{-1}A^{-1}$. What do you notice?   



	\end{enumerate}

\item In part (a) we saw that the matrix product $B^{-1}A^{-1}$ was the inverse of the matrix product $AB$. Now we address the question of whether this is true in general.  Suppose now that $C$ and $D$ are invertible $n \times n$ matrices so that the matrix inverses $C^{-1}$ and $D^{-1}$ exist. 
	\begin{enumerate}[i.]
	\item Use matrix algebra to simplify the matrix product $(CD)\left(D^{-1}C^{-1}\right)$. (Hint: What do you know about $DD^{-1}$ and $CC^{-1}$?)



	\item Simplify the matrix product $\left(D^{-1}C^{-1}\right)(CD)$ in a manner similar to part i.  
	
	
	
	\item What conclusion can we draw from parts i and ii? Explain. What property of matrix multiplication requires us to reverse the order of the product when we create the inverse of $CD$?  
	
	
	
	\end{enumerate}

\ea

\end{activity} 



Activity \ref{act:2_c_5} gives us one important property of matrix inverses. The other properties given in the next theorem can be verified similarly.



\begin{theorem} \label{thm:inverse_properties} Let $A$ and $B$ be invertible $n \times n$ matrices. Then
\begin{enumerate}
\item $\left(A^{-1}\right)^{-1} = A$.
\item The product $AB$ is invertible and  $(AB)^{-1} = B^{-1}A^{-1}$.
\item The matrix $A^{\tr}$ is invertible and $\left(A^{\tr}\right)^{-1} = \left(A^{-1}\right)^{\tr}$.
\end{enumerate}
\end{theorem}

\csection{Examples}

\ExampleIntro

\begin{example} For each of the following matrices $A$,
\begin{itemize}
\item Use appropriate technology to find the reduced row echelon form of $[A \ | \ I_3]$. 

\item Based on the result of part (a), is $A$ invertible? If yes, what is $A^{-1}$? If no, explain why.

\item Let $\vx = \left[ \begin{array}{c} x_1\\x_2\\x_3 \end{array} \right]$ and $\vb = \left[ \begin{array}{c} 5\\4\\1 \end{array} \right]$. If $A$ is invertible, solve the matrix equation $A \vx = \vb$ using the inverse of $A$. If $A$ is not invertible, find all solutions, if any, to the equation $A \vx = \vb$ using whatever method you choose. 
\end{itemize}

\ba
\item $A = \left[ \begin{array}{crr} 1&2&3 \\ 1&-1&-1 \\ 1&0&1 \end{array} \right]$
\item $A = \left[ \begin{array}{crr} 1&2&5 \\ 1&-1&-1 \\ 1&0&1 \end{array} \right]$
\ea

\ExampleSolution
\ba
\item With $A = \left[ \begin{array}{crr} 1&2&3 \\ 1&-1&-1 \\ 1&0&1 \end{array} \right]$, we have the following.
\begin{itemize}
\item The reduced row echelon form of $[A \ | \ I_3]$ is 
\[ \left[ \renewcommand{\arraystretch}{1.4}  \begin{array}{ccc|rrr} 1&0&0&\frac{1}{2}&1&-\frac{1}{2} \\ 0&1&0&1&1&-2  \\ 0&0&1&-\frac{1}{2}&-1&\frac{3}{2} \end{array} \right].\]
\item Since $A$ is row equivalent to $I_3$, we conclude that $A$ is invertible. The reduced row echelon form of $[A \ | \ I_3]$ tells us that 
\[A^{-1} = \frac{1}{2} \left[ \begin{array}{rrr} 1&2&-1 \\ 2&2&-4 \\ -1&-2&3 \end{array} \right].\]
\item The solution to $A \vx = \vb$ is given by 
\[vx = A^{-1} \vb = \frac{1}{2} \left[ \begin{array}{rrr} 1&2&-1 \\ 2&2&-4 \\ -1&-2&3 \end{array} \right] \left[ \begin{array}{c} 5\\4\\1 \end{array} \right] = \left[ \begin{array}{r} 6\\7\\-5 \end{array} \right].\]
\end{itemize}

\item With $A = \left[ \begin{array}{crr} 1&2&5 \\ 1&-1&-1 \\ 1&0&1 \end{array} \right]$, we have the following.
\begin{itemize}
\item The reduced row echelon form of $[A \ | \ I_3]$ is 
\[ \left[ \begin{array}{ccc|crr} 1&0&1&0&0&1 \\ 0&1&2&0&-1&1  \\ 0&0&0&1&2&-3 \end{array} \right].\]
\item Since $A$ is not row equivalent to $I_3$, we conclude that $A$ is not invertible. 
\item The reduced row echelon form of $[A \ | \ \vb]$ is 
\[ \left[ \begin{array}{ccc|c} 1&0&1&0 \\ 0&1&2&0 \\ 0&0&0&1 \end{array} \right].\]
The fact that the augmented column is a pivot column means that the equation $A \vx = \vb$ has no solutions. 
\end{itemize}

\ea


\end{example}

\begin{example} ~
\ba
\item Let $A = \left[ \begin{array}{ccc} 0&1&0\\0&0&1\\0&0&0 \end{array} \right]$. 
	\begin{enumerate}[i.]
	\item Show that $A^2 \neq 0$ but $A^3 = 0$. 
	
	\item Show that $I - A$ is invertible and find its inverse. Compare the inverse of $I-A$ to $I+A+A^2$. 
	
	\end{enumerate}

\item Let $M$ be an arbitrary square matrix such that $M^3 = 0$. Show that $M$ is invertible and find an inverse for $M$.

\ea


\ExampleSolution
\ba
\item Let $A = \left[ \begin{array}{ccc} 0&1&0\\0&0&1\\0&0&0 \end{array} \right]$. 
	\begin{enumerate}[i.]
	\item Using technology to calculate $A^2$ and $A^3$ we find that $A^3=0$ while $A^2 =  \left[ \begin{array}{ccc} 0&0&1\\0&0&0\\0&0&0 \end{array} \right]$.
	
	\item For this matrix $A$ we have $I - A = \left[ \begin{array}{crr} 1&-1&0\\0&1&-1\\0&0&1 \end{array} \right]$. The reduced row echelon form of $I-A$ is 
	\[\left[ \begin{array}{ccc|ccc} 1&-0&0&1&1&1\\0&1&0&0&1&1\\0&0&1&0&0&1 \end{array} \right],\]
	so $I-A$ is invertible and $(I-A)^{-1} = \left[ \begin{array}{ccc} 1&1&1\\0&1&1\\0&0&1 \end{array} \right]$. 
	
A straightforward matrix calculation also shows that 
\[(I-A)^{-1} = I+A+A^2.\]
	
	\end{enumerate}

\item We can try to emulate the result of part (a) here. Expanding using matrix operations gives us
\begin{align*}
(I-M)(I+M+M^2) &= (I+M+M^2) - (M+M^2+M^3) \\
	&= (I+M+M^2) - (M+M^2+0) \\
	&= I
\end{align*}
and
\begin{align*}
(I+M+M^2)(I-M) &= (I+M+M^2) - (M+M^2+M^3) \\
	&= (I+M+M^2) - (M+M^2+0) \\
	&= I.
\end{align*}	 
So $I-M$ is invertible and $(I-M)^{-1} = I+M+M^2$. 

This argument can be generalized to show that if $M$ is a square matrix and $M^n = 0$ for some positive integer $n$, then $I-M$ is invertible and 
\[(I-M)^{-1} = I+M+M^2+ \cdots + M^{n-1}.\] 

\ea


\end{example}

\csection{Summary}
\begin{itemize}
\item If $A$ is an $n \times n$ matrix, then $A$ is invertible if there is a matrix $B$ so that $AB = BA = I_n$. The matrix $B$ is called the inverse of $A$ and is denoted $A^{-1}$.
\item An $n \times n$ matrix $A$ is invertible if and only if $A$ the reduced row echelon form of $A$ is the $n \times n$ identity matrix $I_n$. 
\item To find the inverse of an invertible $n \times n$ matrix $A$, augment $A$ with the identity and row reduce. If $[A \ | \ I_n] \sim [I_n \ | \ B]$, then $B = A^{-1}$.
\item If $A$ and $B$ are invertible $n \times n$ matrices, then $(AB)^{-1}=B^{-1}A^{-1}$. Since the inverse of $AB$ exists, the product of two invertible matrices is an invertible matrix. 
\item We can use the algebraic tools we have developed for matrix operations to solve equations much like we solve equations with real variables. We must be careful, though, to only multiply by inverses of invertible matrices, and remember that matrix multiplication is not commutative. 
\end{itemize}




\csection{Exercises}

\be


\item \label{ex:2_c_unique_inverse} Let $A$ be an invertible $n \times n$ matrix. In this exercise we will prove that the inverse of $A$ is unique. To do so, we assume that both $B$ and $C$ are inverses of $A$, that is $AB=BA = I_n$ and $AC=CA = I_n$. By considering the product $BAC$ simplified in two different ways, show that $B=C$, implying that the inverse of $A$ is unique. 

\item \label{ex:2_c_2by2_inverse} Let $A = \left[ \begin{array}{cc} a&b \\ c&d \end{array} \right]$ be an arbitrary $2 \times 2$ matrix. 
	\ba
	\item If $A$ is invertible, perform row operations to determine a row echelon form of $A$. (Hint: You may need to consider different cases, e.g., when $a=0$ and when $a \neq 0$.)

	\item Under certain conditions, we can row reduce $[A \ | \ I_2]$ to $[I_2 \ | \ B]$, where 
\[B=\frac{1}{ad-bc} \left[ \begin{array}{rr} d&-b \\ -c&a \end{array} \right].\]
Use the row echelon form of $A$ from part (a) to find conditions under which the $2 \times 2$ matrix $A$ is invertible. Then derive the formula for the inverse $B$ of $A$. 
	\ea

\item \ba 
\item For a few different $k$ values, find the inverse of $A = \left[ \begin{array}{cc} 1&k \\ 0&1 \end{array} \right]$. From these results, make a conjecture as to what $A^{-1}$ is in general.

\item Prove your conjecture using the definition of inverse matrix. 

\item Find the inverse of $A = \left[ \begin{array}{ccc} 1&k&\ell \\ 0&1&m\\0&0&1 \end{array} \right]$.
\ea

(Note: You can combine the first two parts above by applying the inverse finding algorithm directly on $A = \left[ \begin{array}{cc} 1&k \\ 0&1 \end{array} \right]$.)

\item Solve for the matrix $A$ in terms of the others in the following equation:
\[ P^{-1}(D+CA)P=B\]
If you need to use an inverse, assume it exists.

\item For which $c$ is the matrix $A=\left[ \begin{array}{ccr} 1&2&-1\\2&1&1\\1&5&c\end{array} \right]$ invertible?

\item For which $c$ is the matrix $A=\left[ \begin{array}{cc} c&2\\3&c\end{array} \right]$ invertible?

\item Let $A$ and $B$ be invertible $n \times n$ matrices. Verify the remaining properties of Theorem \ref{thm:inverse_properties}. That is, show that 	
	\ba
	\item  $\left(A^{-1}\right)^{-1} = A$.
	\item The matrix $A^{\tr}$ is invertible and $\left(A^{\tr}\right)^{-1} = \left(A^{-1}\right)^{\tr}$.
	\ea

\item Label each of the following statements as True or False. Provide justification for your response.
\ba
\item \textbf{True/False} If $A$ is an invertible matrix, then for any two matrices $B, C$, $AB=AC$ implies $B=C$.

\item \textbf{True/False} If $A$ is invertible, then so is $AB$ for any matrix $B$.

\item \textbf{True/False} If $A$ and $B$ are invertible $n\times n$ matrices, then so is $AB$.


\item \textbf{True/False} If $A$ is an invertible $n\times n$ matrix, then the equation $A\vx=\vb$ is consistent for any $\vb$ in $\R^n$.

\item \textbf{True/False} If $A$ is an invertible $n\times n$ matrix, then the equation $A\vx=\vb$ has a unique solution when it is consistent.

\item \textbf{True/False} If $A$ is invertible, then so is $A^2$.

\item \textbf{True/False} If $A$ is invertible, then it reduces to the identity matrix.

\item \textbf{True/False} If a matrix is invertible, then so is its transpose.

\item \textbf{True/False} If $A$ and $B$ are invertible $n\times n$ matrices, then $A+B$ is invertible.

\item \textbf{True/False} If $A^2=0$, then $I+A$ is invertible.

\ea
\ee


\csection{Project: The Richardson Arms Race Model}

How and why a nation arms itself for defense depends on many factors. Among these factors are the offensive military capabilities a nation deems its enemies have, the resources available for creating military forces and equipment, and many others. To begin to analyze such a situation, we will need some notation and background. In this section we will consider a two nation scenario, but the methods can be extended to any number of nations. In fact, after World War I, Richardson collected data and created a model for the countries Czechoslovakia, China, France, Germany, England, Italy, Japan, Poland, the USA, and the USSR.\footnote{The Union of Soviet Socialist Republics (USSR), headed by Russia, was a confederation of socialist republics in Eurasia. The USSR disbanded in 1991. Czechoslovakia was a sovereign state in central Europe that peacefully split into the Czech Republic and Slovakia in 1993.}

Let $N_1$ and $N_2$ represent $2$ different nations. Each nation has some military capability (we will call this the \emph{armament} of the nation) at time $n$ (think of $n$ as representing the year). Let $a_1(n)$ represent the armament of nation $N_1$ at time $n$, and $a_2(n)$ the armament of nation $N_2$ at time $n$. We could measure $a_i(n)$ in weaponry or dollars or whatever units make sense for armaments. The Richardson arms race model provides connections between the armaments of the two nations. 

\begin{pactivity} \label{act:arms_race_1}  We continue to analyze a two nation scenario. Let us suppose that our two nations are Iran (nation $N_1$) and Iraq (nation $N_2$). In 1980, Iraq invaded Iran resulting in a long and brutal 8 year war. Richardson was interested in analyzing data to see if such wars could be predicted by the changes in armaments of each nation. We construct the two nation model in this activity. 
	
During each time period every nation adds or subtracts from its armaments. In our model, we will consider three main effects on the changes in armaments: the defense effect, fatigue effect and the grievance effect. In this activity we will discuss each effect in turn and then create a model to represent a two nation arms race. 
	
\begin{itemize}
\item We first consider the defense effect. In a two nation scenario, each nation may react to the potential threat implied by an arms buildup of the other nation. For example, if nation $N_1$ feels threatened by nation $N_2$ (think of South and North Korea, or Ukraine and Russia, for example), then nation $N_2$'s level of armament might cause nation $N_1$ to increase its armament in response. We will let $\delta_{12}$ represent this effect of nation $N_2$'s armament on the armament of nation $N_1$. Nation $N_1$ will then increase (or decrease) its armament in time period $n$ by the amount $\delta_{12}a_2(n-1)$ based on the armament of nation $N_2$ in time period $n-1$. We will call $\delta_{12}$ a \emph{defense coefficient}.\footnote{Of course, there are many other factors that have not been taken into account in the analysis. A nation may have heavily armed allies (like the U.S.) which may provide enough perceived security that this analysis is not relevant. Also, a nation might be a neutral state, such as Switzerland, and this analysis might not apply to such nations.}


\item Next we discuss the fatigue effect. Keeping a strong defense is an expensive and taxing enterprise, often exacting a heavy toll on the resources of a nation. For example, consider the fatigue that the U.S. experienced fighting wars in Iraq and Afghanistan, losing much hardware and manpower in these conflicts. Let $\delta_{ii}$ represent this \emph{fatigue factor} on nation $i$. Think of $\delta_{ii}$ as a measure of how much the nation has to replace each year, so a positive fatigue factor means that the nation is adding to its armament. The fatigue factor produces an effect of $\delta_{ii}a_i(n-1)$ on the armament of nation $i$ at time $t=n$ that is the effect of the armament at time $t=n-1$. 


\item The last factor we consider is what we will call a grievance factor. This can be thought of as the set of ambitions and/or grievances against other nations (such as the acquisition or reacquisition of territory currently belonging to another country). As an example, Argentina and Great Britain both claim the Falkland Islands as territory. In 1982 Argentina invaded the disputed Falkland Islands which resulted in a two-month long undeclared Falkland Islands war, which returned control to the British. It seems reasonable that one nation might want to have sufficient armament in place to support its claim if force becomes necessary. Assuming that these grievances and ambitions have a constant impact on the armament of a nation from year to year, let $g_i$ be this ``grievance" constant for nation $i$.\footnote{It might be possible for $g_i$ to be negative if, for example, a nation feels that such disputes can and should only be settled by negotiation.} The effect a grievance factor $g_i$ would have on the armament of nation $i$ in year $n$ would be to add $g_i$ directly to $a_i(n-1)$, since the factor $g_i$ is constant from year to year (paying for arms and soldier's wages, for example) and does not depend on the amount of existing armament.

\end{itemize} 

\ba
\item  Taking the three effects discussed above into consideration, explain why  
\[a_1(n) = \delta_{11}a_1(n-1) + \delta_{12}a_2(n-1) + a_1(n-1) + g_1.\]
Then explain why 
\begin{equation} \label{eq:AR_1}
a_1(n) = \left(\delta_{11}+1\right)a_1(n-1) + \delta_{12}a_2(n-1) + g_1. 
\end{equation}

\item Write an equation similar to equation (\ref{eq:AR_1})  that describes $a_2(n)$ in terms of the three effects. \\


\item Let $\va_n = \left[ \begin{array}{ccc} a_1(n) \\ a_2(n)  \end{array} \right]$. Explain why 
\[\va_n = (D+I_2)\va_{n-1} + \vg,\]
where $D = \left[ \begin{array}{cc} \delta_{11}&\delta_{12} \\ \delta_{21}&\delta_{22} \end{array} \right]$ and $\vg = [g_1 \ g_2]^{\tr}$. 


\ea

\end{pactivity}

\begin{table}[h]
\begin{center}
\begin{tabular}{lcc}
Year			& Iran 		& Iraq \\ \hline 
$1966$		&$662$		&$391$ \\ \hline	
$1967$		&$903$		&$378$ \\ \hline	
$1968$		&$1090$		&$495$ \\ \hline	
$1969$		&$1320$		&$615$ \\ \hline	
$1970$		&$1470$		&$600$ \\ \hline	
$1971$		&$1970$		&$618$ \\ \hline	
$1972$		&$2500$		&$589$ \\ \hline	
$1973$		&$2970$		&$785$ \\	 \hline
$1974$		&$5970$		&$2990$ \\ \hline 
$1975$		&$7100$		&$1690$
\end{tabular}
\caption{Military Expenditures of Iran and Iraq 1966-1975.}
\label{T:Expenditures}
\end{center}
\end{table}

\begin{pactivity} \label{act:arms_race_2} In order to analyze a specific arms race between nations, we need some data to determine values of the $\delta_{ij}$ and the $g_i$. Table \ref{T:Expenditures} shows the military expenditures of Iran and Iraq in the years leading up to their war in 1975. (The data is in millions of US dollars, adjusted for inflation and is taken from ``World Military Expenditures and Arms Transfers 1966-1975" by the U.S. Arms Control and Disarmament Agency.) We can perform regression (we will see how in a later section) on this data to obtain the following linear approximations:
\begin{align}
a_1(n) &= 2.0780a_1(n-1) - 1.7081a_2(n-1) - 126.9954 \label{eq:arms_race_regression_1} \\
a_2(n) &=  0.9419a_1(n-1) - 1.3283a_2(n-1) - 101.2980.  \label{eq:arms_race_regression_2}
\end{align}
(Of course, the data does not restrict itself to only factors between the two countries, so our model will not be as precise as we might like. However, it is a reasonable place to start.)  Use the regression equations (\ref{eq:arms_race_regression_1}) and (\ref{eq:arms_race_regression_2}) to explain why 
\[D = \left[ \begin{array}{cc} 1.0780&-1.7081 \\  0.94194&-2.3283 \end{array} \right] \ \text{ and } \ \ \vg = [ -126.9954 \ -101.2980]^{\tr}\]
for our Iran-Iraq arms race. 


\end{pactivity}


Activities \ref{act:arms_race_1} and \ref{act:arms_race_2} provide the basics to describe the general arms race model due to Richardson. If we have an $m$ nation arms race with $D = [\delta_{ij}]$ and $\vg = [g_i]$ , then 
\begin{equation} \label{eq:AR_model}
\va_n =  (D+I_m)\va_{n-1}+\vg.
\end{equation}


\begin{pactivity} The idea of an arms race, theoretically, is to reach a point at which all parties feel secure and no additional money needs to be spent on armament. If such a situation ever arises, then the armament of all nations is stable, or in equilibrium. If we have an equilibrium solution, then for large values of $n$ we will have $\va_n = \va_{n-1}$. So to find an equilibrium solution, if it exists, we need to find a vector $\va_E$ so that 
\begin{equation} \label{eq:AR_equilibrium}
\va_E = (D+I)\va_E + \vg
\end{equation}
where $I$ is the appropriate size identity matrix. If $\va_{E}$ exists, we call $\va_E$ an \emph{equilibrium state}.

We can apply matrix algebra to find the equilibrium state vector $\va_E$ under certain conditions. 
	\ba
   \item Assuming that $\va_E$ exists, use matrix algebra and Equation \ref{eq:AR_equilibrium} to show that 
    \begin{equation} \label{eq:AR_equilibrium_2}
    D\va_E + \vg = 0.
    \end{equation}


\item Under what conditions can we be assured that there will always be a unique equilibrium state $\va_{E}$? Explain. Under these conditions, how can we find this unique equilibrium state? Write this equilibrium state vector $\va_{E}$ as a matrix-vector product.

\item Does the arms race model for Iran and Iraq have an equilibrium solution? If so, find it. If not, explain why not. Use technology as appropriate. 

\item Assuming an equilibrium exists and that both nations behave in a way that supports the equilibrium, explain what the appropriate entry of the equilibrium state vector $\va_E$ suggests about what Iran and Iraq's  policies should be. What does this model say about why there might have been war between these two nations? 


\ea

\end{pactivity}



